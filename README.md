## Project Description

This repository aims at developing analytics based on responses from surveys generated by user survey websites and potentially other alternative financial data sources. These projects involves building a systematic infrastructure for comparing and ensembling various machine learning-based forecasting models. It includes the development of a modular time-series forecasting and testing framework and the incorporation of alternative data sources.


#### Project Overview
- This project focuses on creating a modular time-series forecasting and testing framework.
- It includes univariate time-series prediction, feature expansion, and consideration of alternative data sources.

#### Key Goals
1. Develop a modular forecasting and testing framework.
2. Focus on univariate time-series prediction.
3. Incorporate alternative data sources.
4. Identify the best predictors with input from the team.


## Project Structure

- **`main.py`**: The entry point of the pipeline. Initializes and runs the modular pipeline.
- **`imports.py`**: Contains all library imports used across the pipeline.
- **`pipeline.py`**: Core pipeline logic, including data reading, formatting, and executing combinations of operations.
- **`combined_aggregation.py`**: Defines aggregation and combination functions.
- **`utils.py`**: Utility functions to assist with pipeline operations, including metric evaluation and debugging.
- **`smooth.py`**: Smoothing techniques such as moving average and exponential smoothing.
- **`filter.py`**: Filtering methods to preprocess data, such as filling missing values using the Prophet model.

## Modules Overview

### `pipeline.py`
Defines the `Pipeline` class that:
- Reads and formats data.
- Combines aggregated data with indicators.
- Executes a series of operations using specified combinations.
- Outputs processed results and metrics.

### `combined_aggregation.py`
Provides aggregation functions and the `Combo` class for processing data:
- Includes methods for combining data using smoothing and filtering techniques.
- Evaluates performance metrics (RÂ², MAE, MAPE).
- Supports running models with different configurations.

### `utils.py`
Utility functions for:
- Retrieving class methods dynamically.
- Evaluating pipeline metrics and finding optimal configurations.

### `smooth.py`
Implements smoothing techniques such as:
- Moving Average (`smooth1`).
- Exponential Smoothing (`smooth2`).
- Lowess Smoothing (`smooth3`).
- Fourier Transform Smoothing (`smooth4`).

### `filter.py`
Implements filtering methods such as:
- Prophet-based NaN filling (`filter1`).
- Placeholder filters (`filter2`, `filter3`).


   python main.py
   ```
4. **Results**: The pipeline will process the data, train models, and output metrics. Results and intermediate files are saved in the `results/` directory.

